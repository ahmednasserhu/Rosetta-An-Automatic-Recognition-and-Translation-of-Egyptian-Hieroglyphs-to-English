{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yz6iNvJgqKkp",
    "outputId": "32f224e3-c3d7-4e96-e2d4-fe93454efc97"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'detectron2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d6f8704ae19d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# !nvcc --version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'"
     ]
    }
   ],
   "source": [
    "# !nvidia-smi\n",
    "\n",
    "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "\n",
    "import torch, detectron2\n",
    "# !nvcc --version\n",
    "# TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "# CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "# print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "# print(\"detectron2:\", detectron2.__version__)\n",
    "\n",
    "# COMMON LIBRARIES\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# DATA SET PREPARATION AND LOADING\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "# VISUALIZATION\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "# CONFIGURATION\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "# EVALUATION\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "# TRAINING\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "#Load/Save a Checkpoint\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "#BUILD MODEL\n",
    "from detectron2.modeling import build_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hdHVpF4yFdmA"
   },
   "outputs": [],
   "source": [
    "# Takes image path and read it\n",
    "def imageRead(img_path):\n",
    "    return cv2.imread(img_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Sg7IpNfXpnIM"
   },
   "outputs": [],
   "source": [
    "# Copy the File to google drive and chnage the Path\n",
    "# Trained Model: https://drive.google.com/file/d/1BnFD0kZXCFqGeO3SC-ZCUvQfD69vwkPL/view?usp=share_link\n",
    "\n",
    "# Returns Bounding boxes\n",
    "def predictor(image):\n",
    "    ARCHITECTURE = \"mask_rcnn_R_101_FPN_3x\"\n",
    "    CONFIG_FILE_PATH = f\"COCO-InstanceSegmentation/{ARCHITECTURE}.yaml\"\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
    "    # Change the path of the file to your  model.pth file after mounting google Drive\n",
    "    cfg.MODEL.WEIGHTS = 'C:/Users/lenovo/Desktop/New folder (8)/Copy of model_final (1).pth'\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "    model = build_model(cfg)\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    metadata={}\n",
    "    outputs = predictor(image)\n",
    "    boxes = outputs[\"instances\"].pred_boxes.to('cpu')\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "at2tugfpqZ8h"
   },
   "outputs": [],
   "source": [
    "# Returns updated Bounding boxes\n",
    "def contour_detection(image, boxes):\n",
    "    # Perform contour detection using OpenCV\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a list of contours that do not overlap with any of the bounding boxes\n",
    "    undetected_contours = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 0:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            overlaps = False\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = box\n",
    "                if x >= x1 and y >= y1 and x + w <= x2 and y + h <= y2:\n",
    "                    overlaps = True\n",
    "                    break\n",
    "            if not overlaps:\n",
    "                undetected_contours.append(contour)\n",
    "\n",
    "    # Thresholds to control shown boxes\n",
    "    min_ratio_threshold = 0.14\n",
    "    max_ratio_threshold = 2\n",
    "\n",
    "    # Calculate the average area of the detected boxes\n",
    "    total_area = sum([(box[2] - box[0]) * (box[3] - box[1]) for box in boxes])\n",
    "    avg_area = total_area / len(boxes)\n",
    "\n",
    "    # Set the minimum area threshold as a fraction of the average area\n",
    "    min_area_ratio = min_ratio_threshold  # You can adjust this parameter as needed\n",
    "    min_area = avg_area * min_area_ratio\n",
    "\n",
    "    # Set the maximum area threshold as a fraction of the average area\n",
    "    max_area_ratio = max_ratio_threshold  # You can adjust this parameter as needed\n",
    "    max_area = avg_area * max_area_ratio\n",
    "\n",
    "    # Keep only the bounding boxes that have an area greater than the minimum area threshold\n",
    "    boxes = [box for box in boxes if ((box[2] - box[0]) * (box[3] - box[1])) > min_area]\n",
    "\n",
    "    # Remove the bounding boxes that encompass the whole input image\n",
    "    image_area = image.shape[0] * image.shape[1]\n",
    "    boxes = [box for box in boxes if ((box[2] - box[0]) * (box[3] - box[1])) < max_area * image_area]\n",
    "\n",
    "    # Remove the bounding boxes that are completely inside another bounding box\n",
    "    new_boxes = []\n",
    "    for i, box in enumerate(boxes):\n",
    "        is_inside = False\n",
    "        for j, other_box in enumerate(boxes):\n",
    "            if i != j and other_box[0] <= box[0] and other_box[1] <= box[1] and other_box[2] >= box[2] and other_box[\n",
    "                3] >= box[3]:\n",
    "                is_inside = True\n",
    "                break\n",
    "        if not is_inside:\n",
    "            new_boxes.append(box)\n",
    "    boxes = new_boxes\n",
    "\n",
    "    # Remove the bounding boxes that encompass the whole input image\n",
    "    image_area = image.shape[0] * image.shape[1]\n",
    "    boxes = [box for box in boxes if ((box[2] - box[0]) * (box[3] - box[1])) < max_area * image_area]\n",
    "\n",
    "    # Remove the bounding boxes that are mostly inside another bounding box\n",
    "    new_boxes = []\n",
    "    for i, box in enumerate(boxes):\n",
    "        is_inside = False\n",
    "        for j, other_box in enumerate(boxes):\n",
    "            if i != j and box[0] >= other_box[0] and box[1] >= other_box[1] and box[2] <= other_box[2] and box[3] <= \\\n",
    "                    other_box[3]:\n",
    "                overlap_area = (min(box[2], other_box[2]) - max(box[0], other_box[0])) * (\n",
    "                            min(box[3], other_box[3]) - max(box[1], other_box[1]))\n",
    "                if overlap_area / ((box[2] - box[0]) * (box[3] - box[1])) >= 0.7:\n",
    "                    is_inside = True\n",
    "                    break\n",
    "        if not is_inside:\n",
    "            new_boxes.append(box)\n",
    "\n",
    "    return new_boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DLj9iJe7-SHu"
   },
   "outputs": [],
   "source": [
    "# Returns Bounding boxes sorted from left/right => top/bottom\n",
    "def sortBoundingBoxes(boxes):\n",
    "    list_of_tuplesBoxes = [tuple(lst) for lst in boxes]\n",
    "    list_of_tuplesBoxes.sort(key=lambda x: (x[0]))\n",
    "    list_of_tuplesBoxes.sort(key=lambda x: (x[1]))\n",
    "    return list_of_tuplesBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HdkTu9I1-Ri5"
   },
   "outputs": [],
   "source": [
    "def cropBoundingBoxImage(image,boxes):\n",
    "    # Iterate through bounding boxes\n",
    "    imageList=[]\n",
    "\n",
    "    for box in boxes:\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n",
    "\n",
    "        # Define ROI using bounding box coordinates\n",
    "        roi = image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "        # TODO: save or the cropped bounding box image\n",
    "        imageList.append(roi)\n",
    "\n",
    "    return imageList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RXysy8eLAHms"
   },
   "outputs": [],
   "source": [
    "def OCR_Segmentation(imagePath):\n",
    "    image = imageRead(imagePath)\n",
    "    boxes = sortBoundingBoxes(contour_detection(image, predictor(image)))\n",
    "    return cropBoundingBoxImage(image,boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PxKCuQIuBWeB",
    "outputId": "4dfecc4a-2b52-45a5-a764-0aaa9189e053"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "#  Testing final segmentation function\n",
    "img = \"C:/Users/lenovo/Desktop/download-2.png\"\n",
    "\n",
    "imagesList = OCR_Segmentation(img)\n",
    "\n",
    "# To show the images in the Image List\n",
    "for image in imagesList:\n",
    "    cv2.imshow('image',image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
